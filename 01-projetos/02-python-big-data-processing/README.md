<div align="center">
  <img src="../09-databricks-ai-project/assets/jornada.png" alt="Jornada de Dados" width="200"/>

# **Projeto: Python Big Data Processing**

### [Jornada de Dados](https://suajornadadedados.com.br/)

**Projeto prÃ¡tico sobre processamento eficiente de 1 bilhÃ£o de linhas comparando Python, Pandas, Dask, Polars e DuckDB**

[![Projeto](https://img.shields.io/badge/Projeto-Big%20Data-blue?style=for-the-badge)](https://suajornadadedados.com.br/)
[![Python](https://img.shields.io/badge/Python-3.12+-green?style=for-the-badge\&logo=python)](https://python.org)
[![Pandas](https://img.shields.io/badge/Pandas-Data%20Processing-blue?style=for-the-badge\&logo=pandas)](https://pandas.pydata.org/)
[![Dask](https://img.shields.io/badge/Dask-Distributed-orange?style=for-the-badge)](https://dask.org/)
[![Polars](https://img.shields.io/badge/Polars-Fast%20DataFrames-red?style=for-the-badge)](https://pola-rs.github.io/polars/)
[![DuckDB](https://img.shields.io/badge/DuckDB-Analytics-yellow?style=for-the-badge)](https://duckdb.org/)

</div>

-----

## ğŸ“‹ Sobre

Este projeto demonstra como processar eficientemente **1 bilhÃ£o de linhas de dados** (~14GB) usando diferentes abordagens em Python. O desafio Ã© calcular estatÃ­sticas (mÃ­nimo, mÃ©dia e mÃ¡ximo) de temperaturas por estaÃ§Ã£o meteorolÃ³gica, comparando o desempenho de vÃ¡rias bibliotecas e tÃ©cnicas.

**Objetivo Educacional**: Entender as diferenÃ§as de performance entre diferentes abordagens de processamento de dados em Python e aprender a escolher a ferramenta certa para cada cenÃ¡rio de Big Data.

## ğŸ“Š Fluxo do Projeto

```mermaid
graph TD
    A[Arquivo CSV<br/>1 bilhÃ£o de linhas<br/>~14GB] --> B{Abordagem}
    
    B -->|Python Puro| C1[20 min]
    B -->|Pandas| C2[263 seg]
    B -->|Dask| C3[155 seg]
    B -->|Polars| C4[33 seg]
    B -->|DuckDB| C5[14 seg âš¡]
    
    C1 --> D[EstatÃ­sticas por EstaÃ§Ã£o<br/>Min, MÃ©dia, Max]
    C2 --> D
    C3 --> D
    C4 --> D
    C5 --> D
    
    style A fill:#e1f5ff
    style C5 fill:#c8e6c9
    style D fill:#fff3e0
```

## ğŸ¯ Objetivos de Aprendizado

- **Processamento de Big Data**: Aprender tÃ©cnicas para processar grandes volumes de dados eficientemente
- **ComparaÃ§Ã£o de bibliotecas**: Entender quando usar Python puro, Pandas, Dask, Polars ou DuckDB
- **OtimizaÃ§Ã£o de performance**: Identificar gargalos e otimizar cÃ³digo para grandes volumes
- **Streaming de dados**: Processar dados em lotes sem carregar tudo na memÃ³ria
- **Benchmarking**: Comparar performance de diferentes implementaÃ§Ãµes

## ğŸ“ Estrutura do Projeto

```
02-python-big-data-processing/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ create_measurements.py    # Gera arquivo de teste com 1 bilhÃ£o de linhas
â”‚   â”œâ”€â”€ using_python.py            # ImplementaÃ§Ã£o em Python puro
â”‚   â”œâ”€â”€ using_pandas.py           # ImplementaÃ§Ã£o com Pandas
â”‚   â”œâ”€â”€ using_dask.py             # ImplementaÃ§Ã£o com Dask
â”‚   â”œâ”€â”€ using_polars.py           # ImplementaÃ§Ã£o com Polars
â”‚   â”œâ”€â”€ using_duckdb.py           # ImplementaÃ§Ã£o com DuckDB
â”‚   â””â”€â”€ using_bash_and_awk.sh      # ImplementaÃ§Ã£o em Bash + awk
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ measurements.txt          # Arquivo gerado com dados de teste
â”‚   â””â”€â”€ weather_stations.csv      # Lista de estaÃ§Ãµes meteorolÃ³gicas
â”œâ”€â”€ pyproject.toml                # DependÃªncias do projeto
â””â”€â”€ README.md                     # Este arquivo
```

## ğŸ› ï¸ Tecnologias e Ferramentas

- **Python 3.12.1**: Linguagem de programaÃ§Ã£o
- **Pandas**: Biblioteca tradicional para anÃ¡lise de dados
- **Dask**: Processamento paralelo e distribuÃ­do
- **Polars**: Biblioteca moderna e rÃ¡pida para DataFrames
- **DuckDB**: Banco de dados analÃ­tico em memÃ³ria
- **Bash + awk**: Processamento via linha de comando

## ğŸ“¦ PrÃ©-requisitos

- Python 3.12.1 (gerenciado via pyenv)
- Poetry instalado
- EspaÃ§o em disco suficiente (~14GB para o arquivo de dados)
- MemÃ³ria RAM adequada (8GB+ recomendado)

## ğŸš€ Como Usar

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**:
   ```bash
   git clone https://github.com/lvgalvao/data-engineering-roadmap.git
   cd data-engineering-roadmap/01-projetos/02-python-big-data-processing
   ```

2. **Configure a versÃ£o do Python**:
   ```bash
   pyenv install 3.12.1
   pyenv local 3.12.1
   ```

3. **Instale as dependÃªncias**:
   ```bash
   poetry env use 3.12.1
   poetry install --no-root
   poetry lock --no-update
   ```

### ExecuÃ§Ã£o

1. **Gere o arquivo de teste** (isso pode levar ~10 minutos):
   ```bash
   python src/create_measurements.py
   ```
   Este comando gera o arquivo `data/measurements.txt` com 1 milhÃ£o de linhas por padrÃ£o. Para gerar 1 bilhÃ£o, modifique o cÃ³digo.

2. **Execute as diferentes implementaÃ§Ãµes**:
   ```bash
   # Python puro
   python src/using_python.py
   
   # Pandas
   python src/using_pandas.py
   
   # Dask
   python src/using_dask.py
   
   # Polars
   python src/using_polars.py
   
   # DuckDB (mais rÃ¡pido)
   python src/using_duckdb.py
   
   # Bash + awk
   chmod +x src/using_bash_and_awk.sh
   ./src/using_bash_and_awk.sh 1000000
   ```

## ğŸ“š ConteÃºdo Real

### Formato dos Dados

O arquivo `measurements.txt` contÃ©m dados no formato:
```
Hamburg;12.0
Bulawayo;8.9
Palembang;38.8
...
```

Cada linha representa uma mediÃ§Ã£o de temperatura de uma estaÃ§Ã£o meteorolÃ³gica.

### ImplementaÃ§Ãµes DisponÃ­veis

1. **`using_python.py`**: 
   - Processamento linha por linha usando dicionÃ¡rios Python
   - Sem dependÃªncias externas alÃ©m da biblioteca padrÃ£o
   - Tempo estimado: ~20 minutos para 1 bilhÃ£o de linhas

2. **`using_pandas.py`**:
   - Carrega dados em chunks usando `pd.read_csv()` com `chunksize`
   - Processa em lotes para economizar memÃ³ria
   - Tempo estimado: ~263 segundos para 1 bilhÃ£o de linhas

3. **`using_dask.py`**:
   - Usa Dask para processamento paralelo
   - Processa dados em partiÃ§Ãµes distribuÃ­das
   - Tempo estimado: ~155 segundos para 1 bilhÃ£o de linhas

4. **`using_polars.py`**:
   - Usa Polars, biblioteca moderna escrita em Rust
   - Processamento otimizado e rÃ¡pido
   - Tempo estimado: ~33 segundos para 1 bilhÃ£o de linhas

5. **`using_duckdb.py`**:
   - Usa DuckDB para processamento SQL direto em arquivos CSV
   - Mais rÃ¡pido de todas as implementaÃ§Ãµes
   - Tempo estimado: ~14 segundos para 1 bilhÃ£o de linhas

6. **`using_bash_and_awk.sh`**:
   - Processamento via linha de comando Unix
   - Usa `awk` para processamento e `sort` para ordenaÃ§Ã£o
   - Tempo estimado: ~25 minutos para 1 bilhÃ£o de linhas

### Resultados Esperados

Cada implementaÃ§Ã£o produz uma tabela ordenada por nome da estaÃ§Ã£o com:
- `station`: Nome da estaÃ§Ã£o meteorolÃ³gica
- `min_temperature`: Temperatura mÃ­nima registrada
- `mean_temperature`: Temperatura mÃ©dia (arredondada para 1 casa decimal)
- `max_temperature`: Temperatura mÃ¡xima registrada

### Benchmark de Performance

Resultados obtidos em um laptop M1 com 8GB de RAM processando 1 bilhÃ£o de linhas:

| ImplementaÃ§Ã£o | Tempo de ExecuÃ§Ã£o |
|---------------|-------------------|
| Bash + awk    | 25 minutos        |
| Python puro   | 20 minutos        |
| Pandas        | 263 segundos      |
| Dask          | 155.62 segundos   |
| Polars        | 33.86 segundos    |
| **DuckDB**    | **14.98 segundos** |

## ğŸ”— ConexÃµes com a FormaÃ§Ã£o

- **PrÃ©-requisitos**: 
  - Projeto 01 (Data Project Foundations) para entender estruturaÃ§Ã£o de projetos
  - Conhecimento bÃ¡sico de Python
- **PrÃ³ximos passos**: 
  - Projeto 04 (Data Quality Engineering) para aplicar processamento em pipelines de qualidade
  - Projeto 08 (Databricks Data Modeling) para processamento distribuÃ­do em cloud

## ğŸ“– Recursos Adicionais

- [The One Billion Row Challenge (original em Java)](https://github.com/gunnarmorling/1brc)
- [DocumentaÃ§Ã£o do DuckDB](https://duckdb.org/docs/)
- [DocumentaÃ§Ã£o do Polars](https://pola-rs.github.io/polars/)
- [DocumentaÃ§Ã£o do Dask](https://docs.dask.org/)

## ğŸ‘¤ Autor

**Luciano Filho** - [lvgalvaofilho@gmail.com](mailto:lvgalvaofilho@gmail.com)

**Contribuidores**: 
- [Koen Vossen](https://github.com/koenvo) - ImplementaÃ§Ã£o em Polars
- [Arthur JuliÃ£o](https://github.com/ArthurJ) - ImplementaÃ§Ã£o em Python e Bash

---

**Parte da FormaÃ§Ã£o Profissional em Engenharia de Dados - [Jornada de Dados](https://suajornadadedados.com.br/)**
